---
title: 'AI'
date: 2024-07-24T18:29:30-07:00
draft: false
author: "Monica Spisar"
authorLink: "https://monicaspisar.com"
description: 'Resources: AI'
images: 
- "/posts/.../....png"
tags: []
categories: []
resources:
- name: "foo"
  src: "foo.png"
math:
  enable: true
---

## Responsible AI

### Risks / safety
[Situational awareness: The Decade Ahead (Aschenbrenner 2024)](https://situational-awareness.ai/)

### Interpretability
[Mechanistic Interpretability for AI Safety A Review](https://arxiv.org/html/2404.14082v1 "Mechanistic Interpretability for AI Safety A Review")

### Oversight & standards
[Lessons from the FDA for AI - AI Now Institute](https://ainowinstitute.org/lessons-from-the-fda-for-ai)

### Etc.

[Yann LeCun - A Path Towards Autonomous Machine Intelligence](https://www.youtube.com/watch?v=OKkEdTchsiE)

[Reasoning through arguments against taking AI safety seriously: Yoshua Bengio 2024.07.09](https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/)

[Towards a Cautious Scientist AI with Convergent Safety Bounds: Yoshua Bengio 2024.02.26](https://yoshuabengio.org/2024/02/26/towards-a-cautious-scientist-ai-with-convergent-safety-bounds/)

[ADD \/ XOR \/ ROL\: Someone is wrong on the internet \(AGI Doom edition\)](https://addxorrol.blogspot.com/2024/07/someone-is-wrong-on-internet-agi-doom.html)
- [lcamtuf @HalvarFlake FWIW... - Infosec Exchange](https://infosec.exchange/@lcamtuf/112777356046748881)

---

## Defining AGI

[Karpathy tweet 2024.03.18](https://x.com/karpathy/status/1769767792444866958)